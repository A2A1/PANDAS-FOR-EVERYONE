{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 EXPORTING AND IMPORTING DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6 EXPORTING AND IMPORTING DATA\n",
    "In our examples so far, we have been importing data. It is also common practice to export or save out data sets while processing them. Data sets are either saved out as final cleaned versions of data or in intermediate steps. Both of these outputs can be used for analysis or as input to another part of the data processing pipeline.\n",
    "\n",
    "2.6.1 pickle\n",
    "Python has a way to pickle data. This is Python’s way of serializing and saving data in a binary format reading pickle data is also backwards compatible.\n",
    "\n",
    "2.6.1.1 Series\n",
    "Many of the export methods for a Series are also available for a DataFrame. Those readers who have experience with numpy will know that a save method is available for ndarrays. This method has been deprecated, and the replacement is to use the to_pickle method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scientists = pd.read_csv('data/scientists.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name        Born        Died  Age          Occupation\n",
      "0     Rosaline Franklin  1920-07-25  1958-04-16   37             Chemist\n",
      "1        William Gosset  1876-06-13  1937-10-16   61        Statistician\n",
      "2  Florence Nightingale  1820-05-12  1910-08-13   90               Nurse\n",
      "3           Marie Curie  1867-11-07  1934-07-04   66             Chemist\n",
      "4         Rachel Carson  1907-05-27  1964-04-14   56           Biologist\n",
      "5             John Snow  1813-03-15  1858-06-16   45           Physician\n",
      "6           Alan Turing  1912-06-23  1954-06-07   41  Computer Scientist\n",
      "7          Johann Gauss  1777-04-30  1855-02-23   77       Mathematician\n"
     ]
    }
   ],
   "source": [
    "print(scientists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Rosaline Franklin\n",
      "1          William Gosset\n",
      "2    Florence Nightingale\n",
      "3             Marie Curie\n",
      "4           Rachel Carson\n",
      "5               John Snow\n",
      "6             Alan Turing\n",
      "7            Johann Gauss\n",
      "Name: Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "names = scientists['Name']\n",
    "\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pass in a string to the path you want to save\n",
    "names.to_pickle('output/scientists_names_series.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pickle output is in a binary format. Thus, if you try to open it in a text editor, you will see a bunch of garbled characters.\n",
    "\n",
    "If the object you are saving is an intermediate step in a set of calculations that you want to save, or if you know that your data will stay in the Python world, saving objects to a pickle will be optimized for Python as well as in terms of disk storage space. However, this approach means that people who do not use Python will not be able to read the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6.1.2 DataFrame\n",
    "\n",
    "The same method can be used on DataFrame objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scientists.to_pickle('output/scientists_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Rosaline Franklin\n",
      "1          William Gosset\n",
      "2    Florence Nightingale\n",
      "3             Marie Curie\n",
      "4           Rachel Carson\n",
      "5               John Snow\n",
      "6             Alan Turing\n",
      "7            Johann Gauss\n",
      "Name: Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Read data from what we output\n",
    "# for a Series\n",
    "\n",
    "scientist_names_from_pickle = pd.read_pickle(\n",
    "    'output/scientists_names_series.pickle')\n",
    "\n",
    "print(scientist_names_from_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name        Born        Died  Age          Occupation\n",
      "0     Rosaline Franklin  1920-07-25  1958-04-16   37             Chemist\n",
      "1        William Gosset  1876-06-13  1937-10-16   61        Statistician\n",
      "2  Florence Nightingale  1820-05-12  1910-08-13   90               Nurse\n",
      "3           Marie Curie  1867-11-07  1934-07-04   66             Chemist\n",
      "4         Rachel Carson  1907-05-27  1964-04-14   56           Biologist\n",
      "5             John Snow  1813-03-15  1858-06-16   45           Physician\n",
      "6           Alan Turing  1912-06-23  1954-06-07   41  Computer Scientist\n",
      "7          Johann Gauss  1777-04-30  1855-02-23   77       Mathematician\n"
     ]
    }
   ],
   "source": [
    "# for a DataFrame\n",
    "\n",
    "scientists_from_pickle = pd.read_pickle(\n",
    "    'output/scientists_df.pickle')\n",
    "\n",
    "print(scientists_from_pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pickle files are saved with an extension of .p, .pkl, or .pickle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6.2 CSV\n",
    "\n",
    "Comma-separated values (CSV) are the most flexible data storage type. For each row, the column information is separated with a comma. The comma is not the only type of delimiter, however. Some files are delimited by a tab (TSV) or even a semicolon. The main reason why CSVs are a preferred data format when collaborating and sharing data is because any program can open this kind of data structure. It can even be opened in a text editor.\n",
    "\n",
    "The Series and DataFrame have a to_csv method to write a CSV file. The documentation for Series11 and DataFrame12 identifies many different ways you can modify the resulting CSV file. For example, if you wanted to save a TSV file because there are commas in your data, you can change the sep parameter (Appendix O).\n",
    "\n",
    "11. Saving a Series to a CSV file: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.to_csv.html\n",
    "\n",
    "12. Saving a DataFrame to a CSV file: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save a series into a CSV\n",
    "names.to_csv('output/scientist_names_series.csv')\n",
    "\n",
    "# save a dataframe into a TSV,\n",
    "# a tab-separated value\n",
    "\n",
    "scientists.to_csv('output/scientists_df.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6.2.1 Removing Row Numbers From Output\n",
    "\n",
    "If you open the CSV or TSV file created, you will notice that the first “column” looks like the row number of the dataframe. Many times this is not needed, especially when you are collaborating with other people. Keep in mind that this “column” is really saving the “row label,” which may be important. The documentation will show that there is an index parameter with which to write row names (index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# do not write the row names in the CSV output\n",
    "\n",
    "scientists.to_csv('output/scientists_df_no_index.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6.2.2 Importing CSV Data\n",
    "Importing CSV files was illustrated in Section 1.2. This operation uses the pd.read_csv function. In the documentation,13 you can see there are various ways to read in a CSV. Look at Appendix O if you need more information on using function parameters.\n",
    "\n",
    "13. read_csv documentation: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\n",
    "\n",
    "2.6.3 Excel\n",
    "Excel, which is probably the most commonly used data type (or the second most commonly used, after CSVs), has a bad reputation within the data science community, mainly because colors and other superfluous information can easily find its way into the data set, not to mention one-off calculations that ruin the rectangular structure of a data set. Some other reasons of why are listed in Section 1.1. The goal of this book isn’t to bash Excel, but rather to teach you about a reasonable alternative tool for data analytics. In short, the more of your work you can do in a scripting language, the easier it will be to scale up to larger projects, catch and fix mistakes, and collaborate. However, Excel’s popularity and market share is unrivaled. Excel has its own scripting language if you absolutely have to work in it. This will allow you to work with data in a more predictable and reproducible manner.\n",
    "\n",
    "2.6.3.1 Series\n",
    "The Series data structure does not have an explicit to_excel method. If you have a Series that needs to be exported to an Excel file, one option is to convert the Series into a one-column DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert the Series into a DataFrame\n",
    "# before saving it to an Excel file\n",
    "\n",
    "names_df = names.to_frame()\n",
    "\n",
    "import xlwt # this needs to be installed\n",
    "\n",
    "# xls file\n",
    "\n",
    "names_df.to_excel('output/scientists_names_series_df.xls')\n",
    "\n",
    "import openpyxl # this needs to be installed\n",
    "\n",
    "# newer xlsx file\n",
    "\n",
    "names_df.to_excel('output/scientists_names_series_df.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6.3.2 DataFrame\n",
    "From the preceding example, you can see how to export a DataFrame to an Excel file. The documentation14 shows several ways to further fine-tune the output. For example, you can output data to a specific “sheet” using the sheet_name parameter.\n",
    "\n",
    "14. DataFrame to Excel documentation: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_excel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saving a DataFrame into Excel format\n",
    "\n",
    "scientists.to_excel('output/scientists_df.xlsx',\n",
    "                    sheet_name='scientists',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6.4 Feather Format to Interface With R\n",
    "The format called “feather” is used to save a binary object that can also be loaded into the R language. The main benefit of this approach is that it is faster than writing and reading a CSV file between the languages. The general rule of thumb for using this data format is to use it only as an intermediate data format, and to not use the feather format for long-term storage. That is, use it in your code only to pass in data into R; do not use it to save a final version of your data.\n",
    "\n",
    "The feather formatter is installed via conda install -c conda-forge feather-format or pip install feather-format. You can use the to_feather method on a dataframe to save the feather object. Not every dataframe can be converted into a feather object. For example, our current data set contains a column of date values, which at the time of this writing is not supported by feather.15\n",
    "\n",
    "15. Feather dates, ArrowNotImplementedError: https://github.com/wesm/feather/issues/121"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6.5 Other Data Output Types\n",
    "There are many ways Pandas can export and import data. Indeed, to_pickle, to_csv, and to_excel, and to_feather are only some of the data formats that can make their way into Pandas DataFrames. Table 2.4 lists some of these other output formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 2.4 DataFrame Export Methods\n",
    "\n",
    "Export Method             Description\n",
    "\n",
    "to_clipboard              Save data into the system clipboard for pasting\n",
    "\n",
    "to_dense                  Convert data into a regular “dense” DataFrame\n",
    "\n",
    "to_dict                   Convert data into a Python\n",
    "\n",
    "dict to_gbq               Convert data into a Google BigQuery table\n",
    "\n",
    "to_hdf                    Save data into a hierarchal data format (HDF)\n",
    "\n",
    "to_msgpack                Save data into a portable JSON-like binary\n",
    "\n",
    "to_html                   Convert data into a HTML table\n",
    "\n",
    "to_json                   Convert data into a JSON string\n",
    "\n",
    "to_latex                  Convert data into a LATEX tabular environment\n",
    "\n",
    "to_records                Convert data into a record array\n",
    "\n",
    "to_string                 Show DataFrame as a string for stdout\n",
    "\n",
    "to_sparse                 Convert data into a SparceDataFrame\n",
    "\n",
    "to_sql                    Save data into a SQL database\n",
    "\n",
    "to_stata                  Convert data into a Stata dta file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more complicated and general data conversions (not necessarily just exporting data), the odo library16 has a consistent way to convert between data formats (Appendix T).\n",
    "\n",
    "16. odo library http://odo.readthedocs.org/en/latest/\n",
    "\n",
    "2.7 CONCLUSION\n",
    "This chapter went in a little more detail about how the Pandas Series and DataFrame objects work in Python. There were some simpler examples of data cleaning shown, along with a few common ways to export data to share with others. Chapters 1 and 2 should give you a good basis on how Pandas works as a library.\n",
    "\n",
    "The next chapter covers the basics of plotting in Python and Pandas. Data visualization is not only used in the end of an analysis to plot results, but also is heavily utilized throughout the entire data pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
